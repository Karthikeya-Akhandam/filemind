from typing import Tuple, Optional
import faiss
import numpy as np
from . import config

# The dimension of the embeddings generated by bge-small-en-v1.5
EMBEDDING_DIM = 384

class VectorStore:
    _instance: Optional['VectorStore'] = None
    
    def __init__(self):
        self.index = self._load_or_create_index()

    def _load_or_create_index(self):
        """Loads the FAISS index from disk, or creates a new one if not found."""
        if config.FAISS_INDEX_PATH.exists():
            print(f"Loading existing FAISS index from {config.FAISS_INDEX_PATH}")
            return faiss.read_index(str(config.FAISS_INDEX_PATH))
        else:
            print("No FAISS index found, creating a new one.")
            # Using IndexFlatIP as specified in the plan.
            # IP = Inner Product. With normalized vectors, this is equivalent to cosine similarity.
            return faiss.IndexFlatIP(EMBEDDING_DIM)

    def save(self):
        """Saves the current FAISS index to disk."""
        print(f"Saving FAISS index to {config.FAISS_INDEX_PATH}")
        faiss.write_index(self.index, str(config.FAISS_INDEX_PATH))

    def add(self, embeddings: np.ndarray):
        """
        Adds a batch of embeddings to the index.
        Expects a numpy array of shape (n_vectors, EMBEDDING_DIM).
        """
        if embeddings.ndim != 2 or embeddings.shape[1] != EMBEDDING_DIM:
            raise ValueError(f"Embeddings must have shape (*, {EMBEDDING_DIM})")
        
        # FAISS requires float32
        self.index.add(embeddings.astype(np.float32))

    def search(self, query_vector: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:
        """
        Searches the index for the top k nearest neighbors.

        Args:
            query_vector: A numpy array of shape (1, EMBEDDING_DIM).
            k: The number of neighbors to retrieve.

        Returns:
            A tuple of (distances, indices).
        """
        if self.index.ntotal == 0:
            return np.array([]), np.array([])
            
        if query_vector.ndim != 2 or query_vector.shape[1] != EMBEDDING_DIM:
            raise ValueError(f"Query vector must have shape (1, {EMBEDDING_DIM})")

        return self.index.search(query_vector.astype(np.float32), k)

    @classmethod
    def get_instance(cls) -> 'VectorStore':
        """Gets the singleton instance of the VectorStore."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

# Convenience functions to be used by other modules
def get_vector_store() -> VectorStore:
    """Returns the singleton instance of the vector store."""
    return VectorStore.get_instance()
